{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Reshape, Lambda, BatchNormalization\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.resnet_v2 import preprocess_input\n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(23, 267))\n",
    "\n",
    "x = LSTM(128, return_sequences=True, kernel_initializer='he_normal', name='lstm1')(input)\n",
    "x = LSTM(128, return_sequences=True, kernel_initializer='he_normal', name='lstm2')(x)\n",
    "x = LSTM(128, kernel_initializer='he_normal', name='lstm3')(x)\n",
    "x = Dense(2, kernel_initializer='he_normal',name='dense1')(x)\n",
    "x = Activation('softmax', name='softmax')(x)\n",
    "model = Model(input, x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ai_data/sampling_256_train.pickle','rb') as f:\n",
    "    train_dataset=pickle.load(f)\n",
    "with open('./ai_data/label_256_train.pickle','rb') as f:\n",
    "    train_label=pickle.load(f)\n",
    "\n",
    "with open('./ai_data/sampling_256_val.pickle','rb') as f:\n",
    "    val_dataset=pickle.load(f)\n",
    "with open('./ai_data/label_256_val.pickle','rb') as f:\n",
    "    val_label=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "class Metrics(Callback):\n",
    "\n",
    "    def __init__(self, val_data,val_label,batch_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.validation_data = val_data\n",
    "        self.validation_label = val_label\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_preds = []\n",
    "        y_trues = []\n",
    "        data_gen=iter(self.validation_data)\n",
    "        label_gen=iter(self.validation_label)\n",
    "        for idx in range(len(self.validation_data)):\n",
    "            X = next(data_gen)\n",
    "            y_true=next(label_gen)\n",
    "            y_trues.append([y_true])\n",
    "            y_pred = self.model.predict([X])\n",
    "            y_preds.append(y_pred)\n",
    "\n",
    "\n",
    "        y_true = np.concatenate(y_trues, axis=0)\n",
    "        y_pred = np.concatenate(y_preds, axis=0)\n",
    "        val_true, val_pred = y_true,y_pred\n",
    "        val_true_class = y_true\n",
    "        val_pred_class = np.argmax(val_pred, axis=1)\n",
    "        print(val_pred_class)\n",
    "        cls_report = classification_report(\n",
    "            y_true=val_true_class,\n",
    "            y_pred=val_pred_class,\n",
    "            output_dict=True,\n",
    "            target_names=['0','1'],\n",
    "            labels=np.arange(2)        )\n",
    "        with open('./weights_multi/logs','a') as f:\n",
    "            f.write(str(epoch)+'         '+str(cls_report)+'\\n')\n",
    "        print(cls_report)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    sgd = optimizers.SGD(lr=0.01, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='binary_crossentropy')\n",
    "    filename = './weights_multi/weights-improvement-{epoch:02d}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filename,             \n",
    "                                 monitor='val_loss',   \n",
    "                                 verbose=1,            \n",
    "                                 save_best_only=False,  \n",
    "                                 mode='auto'           \n",
    "                                )\n",
    "    history = model.fit(train_dataset['train'],train_label['train'],\n",
    "                        epochs=10,batch_size=32,callbacks=[checkpoint,Metrics(val_dataset['train'], val_label['train'])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ai_data/sampling_256_test.pickle','rb') as f:\n",
    "    test_dataset=pickle.load(f)\n",
    "with open('./ai_data/label_256_test.pickle','rb') as f:\n",
    "    test_label=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def test_Metrics(val_data,val_label,model):\n",
    "\n",
    "\n",
    "        validation_data = val_data\n",
    "        validation_label = val_label\n",
    "        y_preds = []\n",
    "        y_trues = []\n",
    "        data_gen=iter(validation_data)\n",
    "        label_gen=iter(validation_label)\n",
    "        for idx in range(len(validation_data)):\n",
    "            X = next(data_gen)\n",
    "            y_true=next(label_gen)\n",
    "            y_trues.append([y_true])\n",
    "            y_pred = model.predict([X])\n",
    "            y_preds.append(y_pred)\n",
    "\n",
    "\n",
    "        y_true = np.concatenate(y_trues, axis=0)\n",
    "        y_pred = np.concatenate(y_preds, axis=0)\n",
    "        val_true, val_pred = y_true,y_pred\n",
    "        val_true_class = y_true\n",
    "        val_pred_class = np.argmax(val_pred, axis=1)\n",
    "        print(val_pred_class)\n",
    "        cls_report = classification_report(\n",
    "            y_true=val_true_class,\n",
    "            y_pred=val_pred_class,\n",
    "            output_dict=True,\n",
    "            target_names=['0','1'],\n",
    "            labels=np.arange(2)        )\n",
    "        with open('./weights_multi/logs','a') as f:\n",
    "            f.write(str('result')+'         '+str(cls_report)+'\\n')\n",
    "        print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('./weights_multi/weights-improvement-05.hdf5')\n",
    "\n",
    "test_Metrics(test_dataset['train'], test_label['train'],model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py140",
   "language": "python",
   "name": "py140"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
